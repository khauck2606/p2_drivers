---
title: "100-day mission: Model description"
#date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  bookdown::github_document2:
    # pandoc_args: --webtex
    toc: true
    toc_depth: 5
    toc_float: true
    number_sections: true
  bookdown::pdf_document2: 
    toc: false
    keep_tex: yes
    extra_dependencies: ["float"]
    # extra_dependencies: ["flafter"]
    pandoc_args:
      --filter=pandoc-xnos
    number_sections: true
    fig_caption: yes
    includes:
      in_header: "preamble.tex"
  bookdown::word_document2: 
    toc_depth: 5
    toc_float: true
    number_sections: true
    editor_options: 
      chunk_output_type: inline
bibliography: 
  - "../../../Desktop/work/papers/DAEDALUS.bib"
always_allow_html: true
---


```{r setup, include=FALSE}
library(ggplot2)  
library(knitr)     
library(tidyr)
library(dplyr)
library(stringi)
library(gplots)
library(RColorBrewer)
library(data.table)
library(splines)
library(bookdown)
library(pander)
library(haven)
library(viridis)
library(hrbrthemes)
library(MASS)
library(kableExtra)

panderOptions('round',2)
panderOptions('table.split.table', Inf)

knitr::opts_chunk$set(comment=NA, prompt=FALSE, cache=FALSE, echo=F, results='asis')

format_to_print <- function(x,z=-1){
  formatC(round(x,z), format="f", digits=as.numeric(z>0), big.mark=",")
}

```

```{r,echo=F,warning=F,message=F}

internet <- read.csv('data/API_IT.NET.USER.ZS_DS2_en_csv_v2_5455054.csv',header = F) ## more recent
internet <- internet[-c(1:3),-c(3:63,65:nrow(internet))]
colnames(internet) <- c('country','Country.Code','internet')

# dataset <- read.csv('data/internetdata.csv',stringsAs=F) ## 2015/2016
# internetdata <- subset(dataset,Indicator=='Households w/ Internet access, %'&Subindicator.Type=='% households')
# internetdata$internet <- internetdata$X2016
# icols <- which(grepl('X',colnames(internetdata)))
# for(i in rev(icols)) internetdata$internet[is.na(internetdata$internet)] <- internetdata[[i]][is.na(internetdata$internet)]
# internetdata <- internetdata[,colnames(internetdata)%in%c('Country.ISO3','Country.Name','internet')]
# colnames(internetdata) <- c('Country.Code','country','internet')

incomelevels <- read.csv('data/Metadata_Country_API_IT.NET.USER.ZS_DS2_en_csv_v2_5455054.csv')
colnames(incomelevels)[1] <- 'Country.Code'

incomeint <- left_join(internet,incomelevels,by='Country.Code')
internetplot <- ggplot(subset(incomeint,!is.na(IncomeGroup)&IncomeGroup!='')) +  geom_histogram(aes(x=internet),colour='navyblue',fill='grey') +
  facet_wrap(~IncomeGroup) +
  theme_bw(base_size = 15) +
  labs(x='Internet coverage, % (I)',y='')


hic <- fitdistr(subset(incomeint,!is.na(internet)&IncomeGroup=='High income')$internet/100,"beta",start=list(shape1=1,shape2=1))
mic <- fitdistr(subset(incomeint,!is.na(internet)&IncomeGroup%in%c('Upper middle income'))$internet/100,"beta",start=list(shape1=1,shape2=1))
llmic <- fitdistr(subset(incomeint,!is.na(internet)&IncomeGroup%in%c('Low income','Lower middle income'))$internet/100,"beta",start=list(shape1=1,shape2=1))


strategies <- c('No Closures','School Closures','Economic Closures','Elimination')
income_levels <- c('LLMIC','UMIC','HIC')
vaccination_levels <- c(365,100)
bpsv_levels <- c(0,1)

```


# Simulation rules

- Countries are instantiated with two random variables: the response time, and their importation time
- The response time is the time at which the reporting country reports having seen X hospital cases, where X is a random number between 1 and 20
- The importation time is a random number between 0 and 20 days, where 0 days would be equivalent to the spillover, or origin, country
- The simulation starts at the minimum between the response time and the importation time
- At the response time, the BPSV, if present, is given to people aged 65 and older; testing begins; social distancing begins; economic closures, if in use, are implemented
- At the importation time, five people are moved from compartment S to compartment E
- If closures are being implemented, the rules in Tables \@ref(tab:rulesreactive) and \@ref(tab:ruleselimination) are followed
- The SARS-X--specific vaccine is rolled out starting on day 107 or 372 after the response time, depending on the investment assumption
- All people aged 15 and over are eligible for vaccination, and we assume 80% take it up
- Distribution rate increases linearly to a maximum of 1% of the population per day, at which is stays until 80% coverage is reached
- When vaccine rollout is complete, closures, testing and social distancing end
- When the doubling time is more than 30 days and there are fewer than 1,000 people in hospital, the simulation ends.

| From/to | No closures | Light closures | Heavy closures |
|:----- |:----- |:----- |:----- |
| **No closures** |  |  | t = response time OR Hospital occupancy > 95% capacity |
| **Light closures** | (Growth rate < 0.025 OR Hospital occupancy < 25% capacity) AND vaccine rollout complete OR $R(D(\textbf{1}) < 1$) |  | Hospital occupancy > 95% capacity |
| **Heavy closures** |  | Hospital occupancy < 25% capacity AND t > 7 + response time |  | 

Table: (\#tab:rulesreactive) State transition rules for reactive closure strategies

| From/to | No closures | Light closures | Heavy closures |
|:----- |:----- |:----- |:----- |
| **No closures** |  |  | t = response time OR Hospital occupancy > 95% capacity |
| **Light closures** | Vaccine rollout complete OR $R(D(\textbf{1}) < 1$)  |  | Rt > 1.2 |
| **Heavy closures** | Vaccine rollout complete OR $R(D(\textbf{1}) < 1$)  | Rt < 0.95 AND t > 7 + response time |  | 

Table: (\#tab:ruleselimination) State transition rules for the elimination strategy

# Socio-economic costs


We assign monetary values to YLLs and to years of education in order to add health and education costs of mitigation strategies to the costs of economic closures. We define the total socio-economic costs TSC of an epidemic as the sum of the individual costs:

\begin{equation}
\text{TSC} = L + f_{\text{lives}}(D,l,\text{VLY},r) + (Z_0-Z),
\label{eq:swf}
\end{equation}

where the arguments are the value of school years lost ($L$); the number of deaths per age group due to COVID-19 ($D$), the remaining life expectancy per age group ($l$), the value of a life year (VLY), and discount rate $r$; and the lost output over the period due to reduced economic activity ($Z_0-Z$).


## Lost lives

To value lives lost, we make use of the expected remaining life years per age group [@GlobalBurdenofDiseaseCollaborativeNetwork2021]. These are used to estimate the expected number of years of life lost per death, and to estimate the value of a life year. We map the remaining life expectancy $l_a$ for the GBD age groups $a$ to $l_g$ for the model age groups $g$ as a population-weighted average, taking into account the size of each age group, $N_a$. For the expected number of life years lost per death, we take into account also the probability to die given infection, $P(D|I,a)$:
$$l_g^{\text{(death)}} = \frac{\sum_{a\in g}N_al_aP(D|I,a)}{\sum_{a\in g}N_aP(D|I,a)}; $$
$$l_g^{\text{(life)}} = \frac{\sum_{a\in g}N_al_a}{\sum_{a\in g}N_a}; $$
  
  Expected life years remaining with discounting taken into account can be written
  
```math
\hat{l}_g=\sum_{y=1}^{l_g}\frac{1}{(1+r)^{y}}
```

for discount rate $r>0$. The discounted number of years lost given $D_g$ deaths due to COVID-19 for each age group is 
```math
Y=\sum_gD_g\hat{l}_g^{\text{(death)}}.
```

The VLY used by policy makers should reflect the value that members of the society place on reductions of their own mortality. 
We rely on the intrinsic rather than instrumental interpretation of the valuation of life [@Cutler2020], and we use existing estimates of the value of a statistical life (VSL) to estimate VLY. We interpret the VSL as a population-weighted average [@Ananthapavan2021; @Robinson2021], where each age group has a VSL defined by the number of expected life years remaining, and where each discounted year has the same value: 

\begin{equation}
\text{VSL}=\frac{\sum_gN_g\hat{l}_g^{\text{(life)}}}{\sum_gN_g}\text{VLY}.
\end{equation}


Finally, we define the value of lives lost as 

\begin{equation}
f_{\text{lives}}(D,l^{\text{(death)}},\text{VLY},r)=\text{VLY}*Y.
\end{equation}


## Lost economic output

We measure the cost of economic closures in terms of lost gross value added (GVA): the GDP generated by an economic configuration is the maximum GVA (denoted $z_i$ for each sector $i$) multiplied by the respective sector openings, summed over the period. The maximum possible GDP (which is with no closures) is $Z_0=\frac{T}{365}\sum_{i}z_i$, and we use pre-pandemic output to define the maximum possible values.

$x_{i}(t)$ is the proportion of the workforce contributing to economic production out of the total workforce $N_i$ on day $t$. The workforce can be additionally depleted due to sickness, hospitalisation and death, leaving a smaller fraction ($`\hat{x}_{i}(t)`$) to contribute to production.

```math
\hat{x}_{i}(t)=x_{i}(t)-\sum_{v}\left(I_{S,v,i}(t)+H_{v,i}(t)+D_{v,i}(t)\right)/N_i
```

for vaccine status $v$, infectious and symptomatic $I_S$, hospitalised $H$, deceased $D$, with total population $N_i$ for sector $i$. Then the total GVA for the $T$-day period is: 

```math
Z = \frac{1}{365}\left(\sum_{i\neq\text{ed}}^{\mathcal{N}}\sum_{t=1}^Tz_i\hat{x}_{i}(t) + Tz_{\text{ed}}\right)
```

and the GDP loss compared to the maximum is $Z_0-Z$. All economic sectors contribute GVA according to the level they are open for production, except for the education sector which contributes its maximum possible monthly GVA, $z_{\text{ed}}$ per month.


## Lost education


For the value of a year of education, we use the method of [@Psacharopoulos2021a]. The loss due to school closure is

$$L =  \text{PV}\cdot Y\cdot \alpha\cdot \gamma\cdot \left(S\cdot \beta + (1-\beta)\cdot \int_tI_S(t)dt\right)$$

where PV is the present value of lost earnings:

$$\text{PV} = \frac{1}{S}\sum_aN_a\left( \frac{1-(1+r)^{-(n+20-a)}}{r} -  \frac{1-(1+r)^{-(20-a)}}{r}\right)$$

for discount rate $r=0.03$, number $N_a$ students currently age $a$, and expected number of years of work $n=45$. $Y$ is mean annual earnings, $\alpha$ is the extent and amount of time (in years) schools are closed: 
$$\alpha=\frac{1}{365}\int_{t=1}^{T}(1-x_{ed}(t))dt,$$
$\gamma=0.08$ is the rate of return for one year, $S$ is the total number of students, $\beta$ is the proportion of students affected, and $\int_t I_S(t)dt$ represents education lost due to student sickness with COVID-19. The value $\beta$ represents the ineffectiveness of remote teaching, which we sample as a standard uniform random variable. We note that no strong predictors of effectiveness of remote teaching have been identified [@Patrinos2023]. We assume that losses are linear in duration of school closure, although there is not consensus even on this [@Betthauser2023]. Important factors to include in future work might be those relating to parental circumstances including education level, engagement and socio-economic status [@Moscoviz2022]. However, these factors might be more pertinent to intra- rather than international modelling.




We estimate the average annual income per working-age adult as the total GVA multiplied by the fraction of GVA that goes to labour divided by the number of working-age adults. For the fraction of GVA that goes to labour we use PWT estimates from 2011 (Figure \@ref(fig:labsh)). 

<!-- For the value of a year of education, we use results from [@Psacharopoulos2021a]. For an LIC, the cost of a lost school year is `r round(62*3/.9)`% of GDP. For a UMIC, the cost of a lost school year is `r round(22*3/.9)`% of GDP. For an HIC, the cost of a lost school year is `r round(9*3/.9)`% of GDP. -->

```{r labsh,fig.cap='Fraction of GVA that goes to labour (PWT, 2011).',echo=F,warning=F,message=F}


# L = PV Y alpha \gamma S beta

# L total loss
# PV present value of lost earning
# Y mean annual earnings
# alpha fraction of year
# \gamma rate of return for one year of school
# S number of students
# beta proportion affected

alpha <- 1/3
gamma <- .08
Y <- c(4377, 10470, 32687)
S <- c(141, 1117, 258)*1e6
beta <- .9
dr <- .03
PV <- (1-(1+dr)^(-45))/dr
gdp <- c(.588,31,54)*1e12
# PV*Y*alpha*gamma*S*beta/gdp*100

labs <- setDT(read_dta('data/lab_share_data.dta'))
labs[!is.na(labsh),maxyear:=max(year),by=countrycode]
labincome <- left_join(subset(labs,year==maxyear),incomelevels,by=c('countrycode'="Country.Code"))
labincome <- labincome[,.(labsh,IncomeGroup)]
ggplot(subset(labincome,!is.na(IncomeGroup)&IncomeGroup!='')) + 
  geom_histogram(aes(x=labsh),colour='navyblue',fill='grey') +
  facet_wrap(~IncomeGroup) +
  theme_bw(base_size = 15) +
  labs(x='Labour share of GVA, %',y='')


hic <- fitdistr(subset(labincome,!is.na(labsh)&IncomeGroup=='High income')$labsh,"beta",start=list(shape1=1,shape2=1))
mic <- fitdistr(subset(labincome,!is.na(labsh)&IncomeGroup%in%c('Upper middle income'))$labsh,"beta",start=list(shape1=1,shape2=1))
llmic <- fitdistr(subset(labincome,!is.na(labsh)&IncomeGroup%in%c('Low income','Lower middle income'))$labsh,"beta",start=list(shape1=1,shape2=1))

```

We model these values with Beta distributions. For LLMICs, we have parameters `r round(llmic$estimate['shape1'],2)` and  `r round(llmic$estimate['shape2'],2)`. For UMICs, we have parameters `r round(mic$estimate['shape1'],2)` and  `r round(mic$estimate['shape2'],2)`. For HICs, we have parameters `r round(hic$estimate['shape1'],2)` and  `r round(hic$estimate['shape2'],2)`.

\newpage

```{r,echo=F,warning=F,message=F,include=F}

tvradio <- readxl::read_xlsx('data/DHS_MICS_MIS_assets-for-remote-learning_nat_subnat-1.xlsx')
tvradio <- tvradio[,c(2,13,21,29,56)]

tvradio <- readODS::read_ods('data/educationlosses.ods',col_names=T,sheet=2)

ggplot(subset(tvradio,is.na(mobile)&!country%in%c('sweden','china','botswana'))) +
  geom_label(aes(x=internet,y=`loss per week`,label=country)) + 
  theme_bw(base_size = 15) + labs(x='Internet',y='Education loss per week')
ggplot(subset(tvradio,!is.na(radio))) +
  geom_label(aes(x=radio,y=`loss per week`,label=country)) + 
  theme_bw(base_size = 15) + labs(x='Radio',y='Education loss per week')
ggplot(subset(tvradio,!is.na(tv))) +
  geom_label(aes(x=tv,y=`loss per week`,label=country)) + 
  theme_bw(base_size = 15) + labs(x='Mobile',y='Education loss per week')
ggplot(subset(tvradio,!is.na(mobile))) +
  geom_label(aes(x=mobile,y=`loss per week`,label=country)) + 
  theme_bw(base_size = 15) + labs(x='TV',y='Education loss per week')

```





# Epi model

## Disease state transitions

```{tikz statetransitions, fig.cap = "Disease state transitions. $S$: susceptible. $E$: exposed. $I_A$: asymptomatic infectious. $I_S$: symptomatic infectious. $H$: hospitalised. $R$: recovered. $D$: died. $i$: stratum. $v$: vaccination status.", fig.ext = 'png',echo=F}
\usetikzlibrary{shapes}
\usetikzlibrary{fit}
\usetikzlibrary{arrows}
\usetikzlibrary{positioning,arrows.meta}
\tikzset{
     block/.style={rectangle, draw, fill=red!40, text width=6em,
                   text centered, rounded corners, minimum height=3em},
     arrow/.style={-{Stealth[]}}
}
\tikzstyle{plate} = [draw, rectangle, rounded corners, fit=#1]
\tikzstyle{wrap} = [inner sep=0pt, fit=#1]
\tikzstyle{caption} = [font=\footnotesize, node distance=0] %
\tikzstyle{plate caption} = [caption, node distance=0, inner sep=0pt,
below left=5pt and 0pt of #1.south east] %
\tikzstyle{factor caption} = [caption] %
\tikzstyle{every label} += [caption] %

\newcommand{\plate}[4][]{ %
  \node[wrap=#3,#1] (#2-wrap) {}; % draw box round #3, called #2, with parameters #1
  \node[plate caption=#2-wrap] (#2-caption) {#4}; % fit caption
  \node[plate=(#2-wrap)(#2-caption)] (#2) {}; % draw (used to have #1)
}
\tikzstyle{latent} = [circle,fill=white,draw=black,inner sep=1pt,
minimum size=20pt, font=\fontsize{10}{10}\selectfont, node distance=1]
\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1cm,y=1cm]
    \node[latent] (S) {$S_{i,v}$} ; %
    \node[latent, right=of S] (E1) {$E_{i,v}$} ; %
    \node[latent, right=of E1] (L1) {$I_{S,i,v}$} ; %
    \node[latent, above=of L1] (L2) {$I_{A,i,v}$} ; %
    \node[latent, below=of L1] (I1) {$H_{i,v}$} ; %
    \node[latent, right=of L1] (R) {$R_{i,v}$} ; %
    \node[latent, right=of I1] (D) {$D_{i,v}$} ; %
    \draw [arrow] (S) -- node [above] {$k_1$} (E1);
    \draw [arrow] (E1) -- node [above] {$k_4$} (L1);
    \draw [arrow] (E1) -- node [above] {$k_2$} (L2);
    \draw [arrow] (L1) -- node [left] {$k_6$} (I1);
    \draw [arrow] (L1) -- node [above] {$k_5$} (R);
    \draw [arrow] (L2) edge[bend left=10] node [above] (T6) {$k_3$} (R);
    \draw [arrow] (I1) -- node [above] {$k_7$} (R);
    \draw [arrow] (I1) -- node [above] {$k_8$} (D);
   \plate[inner sep=0.25cm, yshift=0.12cm] {plate3} {(S) (L2) (D)} {$i\in\{1,...,49\}; v\in\{0,1,2\}$}; 
\end{tikzpicture}
```


Possible transitions between disease states are shown in Figure \@ref(fig:statetransitions). Transition rates are functions of time $t$, vaccination status $v$, and group identity $g$ (where the groups are the 45 sectors and the four age groups).

The rate of infection of susceptible individuals, $k_1(v,t)$, is defined as

\begin{equation}
k_1(v,t) = \eta_{A,v}\rho(t)\beta\left(D(x)\cdot I^{(eff)}\right)
(\#eq:infection)
\end{equation}

with

```math
 I^{(eff)}=\sum_{v=0}^2(\epsilon (1-p_3)I_{A,v}+(1-p_4)I_{S,v}). 
```

  Here, $\eta_{A,v}$ is the relative probability to be infected given vaccine status $v$; $\rho(t)$ is the time-dependent modifier of the rate of infection, $\beta$, which captures the impact of social distancing; $D(x)$ is the contact matrix between groups and depends on the economic configuration $x$; $\epsilon$ is the reduction in infectiousness from asymptomatic relative to symptomatic individuals; $p_3$ and $p_4$ are the proportions of asymptomatic and symptomatic infectiousness averted, respectively, due to self isolating; and $I_{\cdot,\cdot}$ is the vector of number of infectious asymptomatic ($I_{A,\cdot}$) and symptomatic ($I_{S,\cdot}$) people who are unvaccinated ($I_{\cdot,0}$), vaccinated with the BPSV ($I_{\cdot,1}$), or vaccinated with the specific vaccine ($I_{\cdot,2}$).

```math
 k_2 = (1-p_S)/\sigma 
```

  is the rate to asymptomatic infectiousness, where $p_S$ is the probability to become symptomatic, and $\sigma$ is the expected duration of the latent period before the onset of infectiousness;

```math
 k_3 = 1/\gamma_A  
```

  is the rate of recovery from asymptomatic infection;

```math
 k_4 = p_S/ \sigma; 
```

  is the rate of symptom onset;

```math
k_5 =  (1-p_H) / \gamma_I 
```

  is the rate of recovery from symptomatic infection, where $p_H$ is the probability to be hospitalised, and $\gamma_I = p_H\gamma_H + (1-p_H)\gamma_R$ is the expected time to be in compartment $I_S$: $\gamma_H$ is the expected duration before hospitalisation and $\gamma_R$ is the expected duration before recovery.
  
```math
p_H=\eta_{H,v}\hat{p}_H
```

  is the baseline probability to be hospitalised ($`\hat{p}_H`$) adjusted by the vaccine effect protecting against hospitalisation ($`\eta_{H,v}`$). Then

```math
k_6 = p_H/\gamma_I
```

  is the rate of hospitalisation following symptomatic infection.

```math
k_7 = (1-p_D) / \lambda_H
```

  is the rate of recovery of hospitalised patients, where $`p_D=\hat{p}_Df_H(H)`$ is the baseline probability to die given hospitalisation, adjusted by a factor encoding the increase in fatality rate as hospital occupancy increases, $`f_H(H)=\max\{1,1+1.87(H-H_{\text{max}})/H_{\text{max}}\}`$. $\lambda_H = p_D\lambda_D + (1-p_D)\lambda_R$ is the expected time to be in compartment $H$: $\lambda_D$ is the expected duration before death and $\lambda_R$ is the expected duration before recovery. $p_D$ is the probability to die given hospitalisation. Finally,

```math
k_8 = p_D/\lambda_H
```

  is the rate of death following hospitalisation.

## Vaccination state transitions

In our model, $v=0$ refers to unvaccinated people, $v=1$ to people who have received a full schedule of BPSV, and $v=2$ to people who have received a full schedule of the specific vaccine. How we model transitions between vaccination states is shown in Figure \@ref(fig:vaccinetransitions).

$w_{0,1}$ represents the rates of BPSV vaccination of unvaccinated susceptible and recovered people, and $w_{1,2}$ represents the rates of vaccinating BPSV-vaccinated susceptible and recovered people. $w_{0,2}$ represents the rates of vaccinating people directly with the specific vaccine. $m_{1}$ and $m_{2}$ are the rates of seroconversion to vaccine-induced immunity, and $k_{12}(t)=k_1(0,t)$ and $k_{19}(t)=k_1(1,t)$ are the rates of infection of just-vaccinated people, which returns them to the epidemiological pathway of the lower vaccination level.

```{tikz vaccinetransitions, fig.cap = "Vaccine state transitions. $S$: susceptible. $M$: vaccinated but not yet protected. $R$: recovered. $v$: vaccination status.", fig.ext = 'png',echo=F}
\usetikzlibrary{shapes}
\usetikzlibrary{fit}
\usetikzlibrary{arrows}
\usetikzlibrary{positioning,arrows.meta}
\tikzset{
     block/.style={rectangle, draw, fill=red!40, text width=6em,
                   text centered, rounded corners, minimum height=3em},
     arrow/.style={-{Stealth[]}}
}
\tikzstyle{plate} = [draw, rectangle, rounded corners, fit=#1]
\tikzstyle{wrap} = [inner sep=0pt, fit=#1]
\tikzstyle{caption} = [font=\footnotesize, node distance=0] %
\tikzstyle{plate caption} = [caption, node distance=0, inner sep=0pt,
below left=5pt and 0pt of #1.south east] %
\tikzstyle{factor caption} = [caption] %
\tikzstyle{every label} += [caption] %

\newcommand{\plate}[4][]{ %
  \node[wrap=#3,#1] (#2-wrap) {}; % draw box round #3, called #2, with parameters #1
  \node[plate caption=#2-wrap] (#2-caption) {#4}; % fit caption
  \node[plate=(#2-wrap)(#2-caption)] (#2) {}; % draw (used to have #1)
}
\tikzstyle{latent} = [circle,fill=white,draw=black,inner sep=1pt,
minimum size=20pt, font=\fontsize{10}{10}\selectfont, node distance=1]
\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1cm,y=1cm]
\clip (-2, -10) rectangle (8, 1);
\node[latent] (S) {$S_{v=0}$} ; %
    \node[latent, draw=white,right=of S] (em) {$...$} ; %
    \node[latent, right=of em] (R) {$R_{v=0}$} ; %
    \node[latent, below=of S] (S01) {$M_{v=1}$} ; %
    \node[latent, below=of S01] (S1) {$S_{v=1}$} ; %
    \node[latent, draw=white,right=of S1] (emv) {$...$} ; %
    \node[latent, right=of emv] (Rv) {$R_{v=1}$} ; %
    \node[latent, below=of S1,yshift=-1cm] (S12) {$M_{v=2}$} ; %
    \node[latent, below=of S12] (S2) {$S_{v=2}$} ; %
    \node[latent, draw=white,right=of S2] (emv2) {$...$} ; %
    \node[latent, right=of emv2] (Rv2) {$R_{v=2}$} ; %
    \draw [arrow] (S) -- node [right] {$w_{0,1}$} (S01);
    \draw [arrow] (S) -- node [above] {} (em);
    \draw [arrow] (em) -- node [above] {} (R);
    \draw [arrow] (S01) -- node [below] {$k_{12}$} (em);
    \draw [arrow] (S12) -- node [right] {$k_{12}$} (em);
    \draw [arrow] (S12) -- node [right] {$k_{19}$} (emv);
    \draw [arrow] (S1) -- node [above] {} (emv);
    \draw [arrow] (emv) -- node [above] {} (Rv);
    % \draw [arrow] (R) edge[bend right] node [above] {$k_{13}$} (S);
    \draw [arrow] (S01) -- node [right] {$m_1$} (S1);
    % \draw [arrow] (Rv) edge[bend right=-30] node [below] {$k_{14}$} (S1);
    % \draw [arrow] (Rv2) edge[bend right=-30] node [below] {$k_{18}$} (S2);
    \draw [arrow] (S) edge[bend right] node [left] {$w_{0,2}$} (S12);
    \draw [arrow] (R) edge[bend left] node [right] {$w_{0,2}$} (Rv2);
    \draw [arrow] (R) -- node [right] {$w_{0,1}$} (Rv);
    \draw [arrow] (S1) -- node [left] {$w_{1,2}$} (S12);
    \draw [arrow] (S12) -- node [right] {$m_2$} (S2);
    \draw [arrow] (Rv) -- node [left] {$w_{1,2}$} (Rv2);
    \draw [arrow] (S2) -- node [above] {} (emv2);
    \draw [arrow] (emv2) -- node [above] {} (Rv2);
\end{tikzpicture}

```

## Contact rates

The configuration $x$ and the proportion of workers working from home $q$ determine the scaling of exposure to infection between different groups for different reasons:

- Worker absence due to sector closure
- Worker absence due to working from home
- Student absence due to school closure
- Customer absence due to sector closure: impact on workers
- Customer absence due to sector closure: impact on customers

We construct contact matrix $D(x)$ as the sum of four matrices: $A(x)$ (community contacts), $B(x)$ (worker-to-worker contacts), $C(x)$ (consumer-to-worker contacts), and  $\hat{C}(x)$ (worker-to-consumer contacts). We construct peacetime matrices ($x=\textbf{1}$) beginning with a "target matrix", which the four matrices should add up to, which is taken from [@Walker2020]. By sampling relevant values, we decompose the whole matrix into its component parts. To incorporate closures, each matrix is transformed independently, before they are all added together again.

Matrix $D(\textbf{1})$ is estimated using as a basis a contact matrix from [@Walker2020]. These are 16-by-16 matrices, $D^{(16)}$, for five-year age bands $a$ up to age group 75+. We map the matrix to a four-by-four matrix $D^{(4)}$ corresponding to the four age groups $g$ used in the DAEDALUS model, using population sizes, $\hat{P}_a$:

```math
D_{gg'}^{(4)} = \frac{\sum_{a\in g}\hat{P}_{a}\sum_{a'\in g'}D^{(16)}_{a,a'}}{\sum_{a\in g}\hat{P}_{a}},
```

and $P_g$ to represent the population sizes of the DAEDALUS age groups,

```math
P_g=\sum_{a\in g}\hat{P}_a.
```

We get to the matrix $D(\textbf{1})$ by broadcasting the four-by-four matrix to the 49-by-49 one. Contacts from all groups $i$ to working groups $j$ depend on the age group of the group ($`g(i)`$), and the fraction of the age-population represented in group $j$, where $w_{j}$ is the number of people in group $j$:

```math
D_{ij}(\textbf{1}) = D^{(4)}_{g(i),g(j)}\frac{w_{j}}{P_{g(j)}}
```

for $i$ and $j$ including all groups (working and non-working). Each group $i$ contains people that belong to only one age group $g$. We refer to the age group of the people in group $i$ as $g(i)$. Then $P_{g(j)}$ is the number of people in the age group of group $j$, so $P_{g(j)}=w_{j}$ for age groups 0 to 4, 5 to 19 and 65+, and $P_{g(j)}=\sum_{j\in\{1,...,N,N+3\}}w_{j}$ for ages 20 to 64. 

In setting up a country, we sample values for $D^{(16)}$ (from which we get $`D(\textbf{1})`$). At the same time, we sample the proportion of contacts that come from workplaces, and workplace-related contacts. From these, we get $B(\textbf{1})$ and $C(\textbf{1})$, constructing the matrices and normalising. 

Matrix B is diagonal and $B_{ii}(\textbf{1})=0$ for $i>N$ [@Haw2020]. Consumer-to-worker contacts (matrix $C$) describe contacts experienced by workers from consumers per sector. Note that $C_{ij}(\textbf{1})=0$ for $i>N$. Matrix $\hat{C}(\textbf{1})$ is the complement of matrix $C(\textbf{1})$, computed by multiplying through by population, transposing, and dividing again by population.

With $D(\textbf{1})$, $C(\textbf{1})$, $B(\textbf{1})$ and $\hat{C}(\textbf{1})$, we learn $A(\textbf{1})$. 

$A$ is decomposed into its constituent parts, representing intra- and inter-household interactions ($L$), school interactions ($S$), hospitality interactions ($H$) and travel interactions ($T$):

```math
A(\textbf{1})=A^{(L)} + A^{(S)}(\textbf{1}) + A^{(H)}(\textbf{1}) + A^{(T)}(\textbf{1})
```

Values for $A^{(S)}(\textbf{1})$ come from sampled values representing the fractions of contacts that come from school. School contacts are estimated separately in two age groups (pre-school age: 0-–4; school age: 5-–19): $A^{(S)}(\textbf{1})$ has entries of zero for groups $g$ not in school, and values for $g$=0 to 4 years old and $g$=5 to 19 year olds. 

Likewise, $A^{(T)}(\textbf{1})$ is also sampled as a fraction of total contacts. $A_{ij}^{(T)}(\textbf{1})\geq 0$ for $i=1,...,N$. $A_{ij}^{(T)}(\textbf{1})=0$ for $i>N$.

Finally, $A^{(H)}(\textbf{1})$ is sampled as a fraction of $A(\textbf{1})- A^{(S)}(\textbf{1}) - A^{(T)}(\textbf{1})$, which leaves $A^{(L)}$.


### Matrix $A$: community contacts

We construct $A(x)$ from its constituent parts, representing intra- and inter-household interactions ($L$), school interactions ($S$), hospitality interactions ($H$) and travel interactions ($T$):

```math
A(x)=A^{(L)} + A^{(S)}(x) + A^{(H)}(x) + A^{(T)}(x).
```

School contacts under $x$ are the peacetime values scaled by the extent of closure. $x_{S}$ is the extent to which schools are open, so that the number of contacts per person scales superlinearly with school closure. 

\begin{equation}
A_{ii}^{(S)}(x)=x_{S}^2A_{ii}^{(S)}(\textbf{1}).
(\#eq:school)
\end{equation}



Matrix  $A^{(T)}$ counts contacts between working people, representing travel. We assume that transport contacts only add to the infection risk if the sector is open and the workers travel to and from their workplace. Again, the value for configuration $x$ is the value for $\textbf{1}$ scaled accordingly:

\begin{equation}
A_{ij}^{(T)}(x) = x_{j}(1-q_i)(1-q_j)A_{ij}^{(T)}(\textbf{1}).
(\#eq:travel)
\end{equation}

$q_i$ is the proportion of workers from sector $i$ working from home, and $(1-q_i)(1-q_j)$ scales contacts between workers superlinearly to approximate the reduced transmission between commuting workers: there should be fewer contacts per person on average, and there should be fewer people having these contacts. 

Also in this equation, $x_{j}$ scales the numbers of contacts linearly with respect to sector closure. At the same time, the number of people in the compartments will be reduced by their sector closure, $x_{i}$. This, in combination with the scaled contacts, leads to superlinear scaling.



Matrix  $A^{(H)}(x)$ gives the contacts made in the hospitality sector:

\begin{equation}
A^{(H)}(x) = x_{H}^2A^{(H)}(\textbf{1})
(\#eq:hosp)
\end{equation}

The value $x_{H}$ is the workforce-weighted average extent to which the hospitality sectors are open, so that the number of contacts per person scales superlinearly according to closure:

```math
x_{H} = \frac{\sum_ix_{i}w_i}{\sum_iw_i}
```

where we sum over only the hospitality sectors.






### Matrix $B$: Worker-to-worker contacts

\begin{equation}
B_{ii}(x) = x_{i}(1-q_i)^2B_{ii}(\textbf{1}),
(\#eq:worker)
\end{equation}

for the $i=1,...,N$ working groups, with the number of contacts adjusted according to at-home working ($q_i$) and sector openness ($x_{i}$). As before, there is superlinear scaling of contacts with respect to working from home. There is linear scaling with respect to sector closure: that is, there are fewer contacts per person, but we do not approximate there being fewer people having them. This is because the latter is accounted for in the movement of people out of the group upon its closure. 

$$B_{ii}(x) = x_{i}^2(1-q_i)^2B_{ii}(\textbf{1})$$

```math
B_{ii}(x) = \hat{x}_i^2B_{ii}(\textbf{1}), \quad \hat{x}_i=\max(x_{i}-q_i,0)
```


### Matrix $C$: Consumer-to-worker contacts

\begin{equation}
C_{ij}(x) = x_{i}(1-q_i)C_{ij}(\textbf{1}),
(\#eq:ctow)
\end{equation}

for $j=1,...,N+3$. 

Here, there is linear scaling of $C_{ij}(\textbf{1})$ with respect to working from home, and linear scaling with respect to sector closure, which becomes superlinear scaling for sectors as individuals are moved out of the compartment, as with matrix $B(x)$.




## Social distancing

We parametrise the effects of 'social distancing' in the model using Google's mobility data (Figure \@ref(fig:smoothmobility)). These changes in mobility were consequences of both government mandates and individual's choices. As we cannot separate the two, we consider a range of possibilities, based on the range of mobility changes observed for a given level of stringency (Figure \@ref(fig:mobilitydrop)). In our model, the mandated economic configuration leads to a change in contacts. We associate the reduction in contacts, which translates as a relative reduction in transmission, with the reduction in mobility. 


```{r smoothmobility,fig.cap='Mobility trajectories in 2020 for all countries, with points showing the point at which the largest drop was observed. Trajectories are averaged over "Retail and recreation", "Transit stations" and "Workplaces" and smoothed with a spline of 80 knots.', echo=F,message=F,warning=F,fig.width=3}
knitr::include_graphics(path = "README_files/figure-gfm/smoothmobility.png")
```

```{r mobilitydrop,fig.cap='The largest drop in mobility from Figure \ref{fig:smoothmobility} is plotted against the stringency on that date.', echo=F,message=F,warning=F}
knitr::include_graphics(path = "README_files/figure-gfm/mobilitydrop.png")
```

- We want to write mobility as a function of mandate and some epi outcome, e.g. deaths: $m = (1-p_8)f(y,g) + p_8$ where $m$ is mobility, $y$ is deaths per million, $g$ is government mandate, and $`0 < p_8 < 1`$ is the baseline.
- We want mobility to drop monotonically with both the mandate and the epi outcome: $\frac{df}{dy}<0$, $\frac{df}{dg}<0$.
- We want a maximum mobility of 1 when both the mandate and the epi outcome are 0: $f(0,0)=1$.
- We want mobility to approach $p_8$ when the mandate and the epi outcome become large: $\lim_{x\to 10^6, g\to 1}f(y,g)= 0$.
- We want to allow for the possibility of redundancy between the two variables: $f(0,0)/f(0,g) > f(x,0)/f(y,g)$ and $f(0,0)/f(y,0) > f(0,g)/f(y,g)$ for $y,g>0$.

A simple model to achieve these criteria is: $$f(y,g) = \frac{1}{1+p_9y+p_{10}g}$$
with $p_9, p_{10}>0$.

However, we might also want a model that can be parametrised with a distribution whose uncertainty covers the whole range of possible eventualities. The equivalent model with compounded effects would be $$f_1(y,g) = \frac{1}{1+p_9y}\frac{1}{1+p_{10}g}.$$ The equivalent model with completely overlapping effects would be $$f_2(y,g) = \frac{1}{1+\max(p_9y,p_{10}g)}.$$ Then we could include 'model uncertainty' via some parameter $\beta\sim\mathcal{U}(0,1)$, defining $$f(y,g) = (f_1(y,g))^{p_{11}}(f_2(y,g))^{(1-p_{11})}.$$

```{r mobilityfitted,fig.cap='Fit of model to data.', echo=F,message=F,warning=F}
knitr::include_graphics(path = "README_files/figure-gfm/mobilityfitted.png")
```

```{r mobilityposterior,fig.cap='Posterior distribution for parameters $p_9$ and $p_8$.', echo=F,message=F,warning=F}
knitr::include_graphics(path = "README_files/figure-gfm/mobilityposterior.png")
```

```{r mobilitycurves,fig.cap='Sampled curves for four levels of mitigation. Data shown as points.', echo=F,message=F,warning=F}
knitr::include_graphics(path = "README_files/figure-gfm/mobilitycurves.png")
```


## Self isolating

We assume that infectious people who know their status have a probability $p_1\sim\mathcal(U)(0,1)$ to self isolate, starting one day into their infectious period. We assume constant infectiousness over time. Then the amount of infectiousness averted of symptomatic people is $p_4=p_1(\gamma_I-\min(1,1/\gamma_I))$, who isolate due to the onset of symptoms, which we assume happens concurrently with onset of infectiousness. The fraction of asymptomatic cases identified by testing is $p_2$. We assume asymptomatic cases have the same probability to self isolate and that test results are returned after one day of infectiousness. Then the infectiousness that testing averts is $p_3=p_1(\gamma_A-\min(1,1/\gamma_A))$. 

<!-- b0    = 2.197; -->
<!-- b1    = 0.1838; -->
<!-- b2    = -1.024; -->
<!-- frac_cases_found = 1./(1+exp(b0+b1*Ip+b2*log10(trate))); -->
<!-- frac_cases_found(Ip >= trate) = min(frac_cases_found(Ip >= trate),trate/10^5); -->
<!-- frac_cases_found = max(frac_cases_found, trate/10^5 ); -->

## Equations

\begin{align}
\frac{dS_{i,v}}{dt} & = m_{v,i}M_{i,v} - \left( k_1(v,t) + \sum_{u=v+1}^{2}w_{v,u,i} \right)S_{i,v} \\
\frac{dM_{i,v}}{dt} & = \sum_{u=0}^{v-1}w_{u,v,i}S_{i,u} -\left( k_1(v,t) + m_{v,i} \right)M_{i,v} \\
\frac{dE_{i,v}}{dt} & = k_1(v,t)(S_{i,v}+M_{i,v-1}) - (k_2+k_4)E_{i,v} \\
\frac{dI_{A,i,v}}{dt} & = k_2E_{i,v} - k_3I_{A,i,v} \\
\frac{dI_{S,i,v}}{dt} & = k_4E_{i,v} - (k_5+k_6)I_{S,i,v} \\
\frac{dR_{i,v}}{dt} & = k_3I_{A,i,v} + k_5I_{S,i,v} + k_7 H_{i,v} - \sum_{u=v+1}^{2}w_{v,u,i}R_{i,v} + \sum_{u=0}^{v-1}w_{u,v,i}R_{i,v-1}\\
\frac{dH_{i,v}}{dt} & = k_6I_{S,i,v} - (k_7 + k_8) H_{i,v} \\
\frac{dD_{i,v}}{dt} & =  k_8 H_{i,v}
\end{align}

$w_{u,v,i}$ is the rate of vaccination from level $u$ to level $v$. $w_{u,v,i}=0$ for $u=2$; $m_{v,i}$ is the rate of maturation of immunity following vaccination. $m_{v,i}=0$ for $v=0$.

# Econ model 

## Configurations

```{r eccon,tab.cap='Economic configurations used to implement strategies. Values are the openness of the sector expressed as a percentage. Elimination values are taken from Australia. Lockdown and Economic Closures values are taken from the UK. School Closures values are taken from Indonesia. ',echo=F,warning=F,message=F}

eccon <- readxl::read_xlsx('data/6.economic_closures.xlsx',sheet='configurations')
for(i in 2:ncol(eccon)) eccon[,i] <- round(eccon[,i]*100)
colorder <- c(2,1,2,3,4,5)
eccon <- eccon[,c(0,colorder)+1]

if (!knitr::is_html_output(excludes = "markdown")) { 
  pander(eccon,caption='Economic configurations used to implement strategies. Values are the openness of the sector expressed as a percentage. Elimination values are taken from Australia. Lockdown and Economic Closures values are taken from the UK. School Closures values are taken from Indonesia. \\label{tab:eccon}')
}else{
    x <- knitr::kable(eccon,escape=F, "html",caption='Economic configurations used to implement strategies. Values are the openness of the sector expressed as a percentage.  Elimination values are taken from Australia. Lockdown and Economic Closures values are taken from the UK. School Closures values are taken from Indonesia. \\label{tab:eccon}')
  kable_styling(x,full_width = F,latex_options = "HOLD_position") %>%
  add_header_above(c('',"Elimination" = 2,"Economic closures" = 2,"School closures" = 2)) %>%
  kable_classic()
}

```



## Impact of tourism


### Food and accommodation services sector

As there is no "tourism" sector in the 45-sector classification we are using, to model the impact of changes to tourism, we identify the "Food and accommodation services" sector with tourism. This is imperfect. The correlation of their % contributions to GDP is 0.64 and the order of magnitude is similar (1 to 7% vs 2 to 10% of GDP). The other two sectors considered (Air transport and Arts, entertainment and recreation) have little correlation with tourism in terms of % of GDP. (See Figure \@ref(fig:pairs).)



```{r pairs, fig.cap="Correlations between tourism-related data. First: https://www.unwto.org/tourism-statistics/key-tourism-statistics. Second to fourth: https://www.unwto.org/tourism-data/international-tourism-and-covid-19. Fifth to seventh: OECD.",fig.height=7, fig.align="center",echo=F,warning=F,message=F}

data <- readODS::read.ods('data/tourism.ods')[[1]]
colnames(data) <- data[1,]
data <- data[-1,]
for(i in 2:ncol(data)) data[,i] <- as.numeric(data[,i])


data$`International tourism as a share of GDP` <- data$`Tourism as a share of GDP (%)`/100 * data$`International tourism as share of total tourism (%)`

panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...) {
  usr <- par("usr")
  on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  keep <- !is.na(x) & !is.na(y)
  Cor <- abs(cor(x[keep], y[keep])) # Remove abs function if desired
  txt <- paste0(prefix, format(c(Cor, 0.123456789), digits = digits)[1])
  if(missing(cex.cor)) {
    cex.cor <- 0.4 / strwidth(txt)
  }
  text(0.5, 0.5, txt,
       cex = 1 + cex.cor * Cor) # Resize the text by level of correlation
}

my.text.panel <- function(labels) {
  function(x, y, lbl, ...) {
  spt <- strsplit(lbl,' ')[[1]]
    newtxt <- spt[1]
    for(i in 2:length(spt)){
      tst <- paste0(newtxt[length(newtxt)],' ',spt[i])
      if(nchar(tst)<15){
        newtxt[length(newtxt)] <- tst
      }else{
        newtxt[length(newtxt)+1] <- spt[i]
      }
    }
    text(x, y, paste0(newtxt,collapse='\n'), ...)
  }
}

pairs(data[,c(11,2:4,7:9)],
      text.panel = my.text.panel(c(Sepal.Length="Slen", Sepal.Width="Swid",
                                   Petal.Length="Plen", Petal.Width="Pwid")),
      upper.panel = panel.cor,    # Correlation panel
      lower.panel = panel.smooth)

```


\newpage


### Sector shrinkage as a result of the pandemic






For many countries, tourism was reduced in the COVID-19 pandemic not because of domestic mandates but because of reduced international travel. Therefore, the fraction of tourism that comes from abroad is a factor that can determine the impact of a pandemic on a country's GDP potentially independently of what happens within the country. (A useful model extension would be to include some dependence on country factors, e.g. case numbers.)

We model mitigation via business closures, which are mandated by sector. We represent openness with values $x$ which range from 0 to 1, 1 representing maximum openness. To capture the impact of reduced international travel, we set the maximum openness of the food and accommodation services sector to be limited by international tourism as:

```math
x = \min\{\hat{x}, 1+ y(z-1)\}
```

where $`\hat{x}`$ is the openness of the sector according to the schedule (i.e. the mitigation strategy), $y$ is the proportion of tourism that is international, and $z$ is the fraction international tourism reduces to as a consequence of the pandemic. I.e. the tourism remaining is the domestic ($1-y$) plus that that comes in from abroad ($yz$).

Therefore, the contribution of the GVA of the food and accommodation services sector is limited either by the pandemic, or by the mitigation measures - whichever is lower.




```{r ,echo=F,warning=F,message=F}


ytd <- readODS::read.ods('data/tourism.ods')[[2]]

colnames(ytd) <- ytd[1,]
ytd <- ytd[-1,]
for(i in 2:ncol(ytd)) ytd[,i] <- as.numeric(ytd[,i])


meltytd <- melt(ytd,id.vars='Country')
meltdata <- melt(data[,c(1:5)],id.vars='Country')
tourismhist <- ggplot() + 
  geom_histogram(data=meltytd,aes(x=value),colour='navyblue',fill='navyblue',bins=30) + 
  geom_histogram(data=meltdata,aes(x=value),colour='white',fill='grey',bins=30) + 
  facet_wrap(~variable,scales='free') +
  theme_bw(base_size = 15) + labs(x='',y='')



library(MASS)
dat <- ytd$`International tourist arrivals, YTD change (%)`/100 + 1
dat <- dat[!is.na(dat)]
fit_params <- fitdistr(dat,"lognormal")

# generate values given our fit parameters
x <- seq(0,max(dat),length=10000)
# hst <- hist(dat, breaks=x)
fit <- dlnorm(x, fit_params$estimate['meanlog'], fit_params$estimate['sdlog'])
```



### Loss of international tourists

We model the distribution of $z$ using data from 2020 (Figure \@ref(fig:tourismhist), bottom-right plot). We fit to it a log-normal distribution, and find mean value `r round(fit_params$estimate['meanlog'],2)` and standard deviation `r round(fit_params$estimate['sdlog'],2)` (Figure \@ref(fig:ytd)). We use these values as inputs for all country models.


```{r tourismhist, fig.cap="Distributions of tourism-related data from https://www.unwto.org/tourism-data/international-tourism-and-covid-19. In grey are the subset of countries for which we have GVA data by sector.",fig.height=6, fig.width=9, fig.align="center",echo=F,warning=F,message=F}
tourismhist
```


```{r ytd, fig.cap="Fit of log-normal distribution to loss-of-tourism data.",fig.height=3, fig.align="center",echo=F,warning=F,message=F,fig.width=4}

ggplot() + geom_histogram(aes(x=dat,y=..density..),colour='navyblue',fill='grey',bins=30) +
  geom_line(aes(x=x,y=fit),colour='navyblue',size=2) +
  theme_bw(base_size=15) +
  scale_x_continuous(expand=c(0,0)) + 
  labs(x='Remaining international tourism (z)',y='Density')

# plot the fit and original distributions
# plot(x, fit, type="l", ylab="Density",
#      xlab="X", ylim=c(0,max(hst$density)), xlim=c(0,2))
# title(main = "Density histogram with lognormal fit")
# lines(hst$mid, hst$density, type="l", col="red")
# legend(8,0.15,legend=c("Fit","Data"),lty=c(1,1),col=c("black","red"))
```



\newpage


### Dependence on international tourism

We model $y$ as a function of the share of GDP that comes from the sector. Note that the data we have for this are biased towards high-income countries.

We write 

$$y\sim\text{Beta}(\alpha(u),\beta(u))$$

where $u$ is the fraction of GDP coming from the Food and accommodation sector. We learn three parameters $p_5$, $p_6$ and $p_7$ to best fit the relationship between $u$ and $y$ in countries we have observations for:

$$p_5 = \alpha(u)+\beta(u)$$

$$p_6u + p_7 = \frac{\alpha(u)}{\alpha(u)+\beta(u)}$$
  
Here, $p_5$ controls the variance of the distribution and $p_6$ and $p_7$ the linear relationship between $u$ and $y$. Using an optimisation routine in R we find $p_5=5.93$, $p_6=3.66$ and $p_7=0.099$. Results are shown in Figure \@ref(fig:sectortourism). We use these values as inputs for all country models.

 ![(\#fig:sectortourism) Predicting the percentage of tourism that comes from abroad as a function of the size of the sector. Each row represents a beta distribution whose mean is determined by the size of the sector (u). Blue points show the data we have available (grey bars in Figure \@ref(fig:tourismhist)).](figures/sectortourism.png){ width=60% }

\newpage

## Remote working


For each sector in each country, we have the 90% interval for the proportion of people who can work from home from [@Gottlieb2021]. We assume that the value we sample within the range is related to internet infrastructure, so that a low value in one sector implies low values in all sectors. We:

- take the subset of countries in the income group (LLMIC / UMIC / HIC);
- take the minimum of the lower bounds by sector (5%);
- take the maximum of the upper bounds by sector (95%);
- sample from a uniform distribution between these bounds, taking the same quantile for each sector.

```{r internet,fig.cap='Internet access by income level. World Bank data for 2019.',echo=F,warning=F,message=F,include=F}
internetplot
```

<!-- We model the Figure \@ref(fig:internet) values with Beta distributions. For LLMICs, we have parameters `r round(llmic$estimate['shape1'],2)` and  `r round(llmic$estimate['shape2'],2)`. For UMICs, we have parameters `r round(mic$estimate['shape1'],2)` and  `r round(mic$estimate['shape2'],2)`. For HICs, we have parameters `r round(hic$estimate['shape1'],2)` and  `r round(hic$estimate['shape2'],2)`. -->

# Parametric distributions


```{r paramdist,tab.cap='Parameter distributions.',echo=F,warning=F,message=F}

paramdist <- read.csv('data/parameter_distributions.csv')
colnames(paramdist) <- c('Parameter','Income group','Distribution','Parameter 1','Parameter 2')
paramdist <- subset(paramdist,Parameter!='bmi')
rownames(paramdist) <- NULL
paramdist$Parameter <- gsub('_',' ',paramdist$Parameter)
paramdist$Parameter <- gsub('pointiness','P1+P2',paramdist$Parameter)
paramdist$Parameter <- gsub('labsh','Labour share of GVA',paramdist$Parameter)
paramdist$Parameter <- gsub('Hmax','Hospital capacity',paramdist$Parameter)
paramdist$Parameter <- gsub('pt','Public transport frac',paramdist$Parameter)
paramdist$Parameter <- gsub('sec','Tourism',paramdist$Parameter)
paramdist$Parameter <- gsub('frac','fraction',paramdist$Parameter)
paramdist$Parameter <- gsub('schoolA1','Nursery contacts',paramdist$Parameter)
paramdist$Parameter <- gsub('schoolA2','School contacts',paramdist$Parameter)
paramdist$Distribution <- gsub('betainv','Beta',paramdist$Distribution)
paramdist$Distribution <- gsub('logninv','Log normal',paramdist$Distribution)
paramdist$Distribution <- gsub('gaminv','Gamma',paramdist$Distribution)
paramdist$`Parameter 1` <- round(paramdist$`Parameter 1`,2)
paramdist$`Parameter 2` <- round(paramdist$`Parameter 2`,2)

lg <- 'Parameter distributions. \\label{tab:paramdist}'
if (!knitr::is_html_output(excludes = "markdown")) { 
  pander(paramdist,caption=lg)
}else{
    x <- knitr::kable(paramdist,escape=F, "html",caption=lg)
  kableExtra::kable_styling(x,full_width = F,latex_options = "HOLD_position")
}

```


## Hospital capacity

```{r hmax,fig.cap='Hospital capacity: available beds minus usual occupancy.',echo=F,warning=F,message=F}


hmaxi <- setDT(read.csv('data/country_data.csv'))
ggplot(subset(hmaxi,!is.na(igroup)&igroup!='')) + 
  geom_histogram(aes(x=Hmax),colour='navyblue',fill='grey') +
  facet_wrap(~igroup) +
  theme_bw(base_size = 15) +
  labs(x='Hospital beds per 100,000',y='')


hic <- fitdistr(subset(hmaxi,!is.na(Hmax)&igroup=='HIC')$Hmax,"gamma")
mic <- fitdistr(subset(hmaxi,!is.na(Hmax)&igroup%in%c('UMIC'))$Hmax,"gamma")
llmic <- fitdistr(subset(hmaxi,!is.na(Hmax)&igroup%in%c('LMIC','LIC'))$Hmax,"gamma")

```

We model these values with gamma distributions. For LLMICs, we have parameters `r round(llmic$estimate['shape'],2)` and  `r round(llmic$estimate['rate'],2)`. For UMICs, we have parameters `r round(mic$estimate['shape'],2)` and  `r round(mic$estimate['rate'],2)`. For HICs, we have parameters `r round(hic$estimate['shape'],2)` and  `r round(hic$estimate['rate'],2)`. (Data sources: World Bank (beds); OECD, WHO euro (bed occupancy rates).)


\newpage

